@book{sutton2011reinforcement,
    title={Reinforcement Learning: An Introduction},
    author={Sutton, Richard S and Barto, Andrew G},
    edition={Second},
    year={2018},
    publisher={MIT Press}
}

@article{wei2022chain,
    title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
    author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
    journal={Advances in Neural Information Processing Systems},
    year={2022}
}

@article{mohamed2020monte,
    title={Monte Carlo Gradient Estimation in Machine Learning},
    author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
    journal={Journal of Machine Learning Research},
    year={2020}
}

@article{glynn1990likelihood,
    title={Likelihood Ratio Gradient Estimation for Stochastic Systems},
    author={Glynn, Peter W},
    journal={Communications of the ACM},
    year={1990}
}

@misc{SpinningUp2018,
    author={Achiam, Joshua},
    title={Spinning Up in Deep Reinforcement Learning},
    year={2018}
}

@inproceedings{zhang2022deeper,
    title={A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms},
    author={Zhang, Shangtong and Laroche, Romain and van Seijen, Harm and Whiteson, Shimon and Tachet des Combes, Remi},
    booktitle={International Conference on Autonomous Agents and Multiagent Systems},
    year={2022}
}

@article{williams1992simple,
    title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
    author={Williams, Ronald J},
    journal={Machine Learning},
    year={1992}
}

@inproceedings{lan2022model,
    title={Model-free Policy Learning with Reward Gradients},
    author={Lan, Qingfeng and Tosatto, Samuele and Farrahi, Homayoon and Mahmood, Rupam},
    booktitle={International Conference on Artificial Intelligence and Statistics},
    year={2022}
}

@inproceedings{li2024remax,
    title={ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models},
    author={Li, Ziniu and Xu, Tian and Zhang, Yushun and Lin, Zhihang and Yu, Yang and Sun, Ruoyu and Luo, Zhi-Quan},
    booktitle={International Conference on Machine Learning},
    year={2024}
}

@inproceedings{kool2019attention,
    title={Attention, Learn to Solve Routing Problems!},
    author={Kool, Wouter and van Hoof, Herke and Welling, Max},
    booktitle={International Conference on Learning Representations},
    year={2019}
}

@article{kool2019buy,
    title={Buy 4 Reinforce Samples, Get a Baseline for Free!},
    author={Kool, Wouter and van Hoof, Herke and Welling, Max},
    booktjournalitle={ICLR 2019 workshop: Deep RL Meets Structured Prediction},
    year={2019}
}

@inproceedings{ahmadian2024back,
    title={Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs},
    author={Ahmadian, Arash and Cremer, Chris and Gall{\'e}, Matthias and Fadaee, Marzieh and Kreutzer, Julia and Pietquin, Olivier and {\"U}st{\"u}n, Ahmet and Hooker, Sara},
    booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    pages={12248--12267},
    year={2024}
}

@inproceedings{schulman2015trust,
    title={Trust Region Policy Optimization},
    author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
    booktitle={International Conference on Machine Learning},
    year={2015}
}

@article{schulman2017proximal,
    title={Proximal Policy Optimization Algorithms},
    author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
    journal={arXiv preprint arXiv:1707.06347},
    year={2017}
}

@inproceedings{schulman2016high,
    title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
    author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
    booktitle={International Conference on Learning Representations},
    year={2016}
}

@article{shao2024deepseekmath,
    title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
    author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Yang and others},
    journal={arXiv preprint arXiv:2402.03300},
    year={2024}
}

@article{yu2025dapo,
    title={DAPO: An Open-Source LLM Reinforcement Learning System at Scale},
    author={Yu, Qiying and Zhang, Zheng and Zhu, Ruofei and Yuan, Yufeng and Zuo, Xiaochen and Yue, Yu and Dai, Weinan and Fan, Tiantian and Liu, Gaohong and Liu, Lingjun and others},
    journal={arXiv preprint arXiv:2503.14476},
    year={2025}
}

@inproceedings{liu2025understanding,
    title={Understanding R1-Zero-Like Training: A Critical Perspective},
    author={Liu, Zichen and Chen, Changyu and Li, Wenjun and Qi, Penghui and Pang, Tianyu and Du, Chao and Lee, Wee Sun and Lin, Min},
    booktitle={Conference on Language Modeling},
    year={2025}
}