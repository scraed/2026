<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Revisiting The NetHack Learning Environment | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="The NetHack Learning Environment (NLE) was proposed as a challenging benchmark to test an agents abilities to perform complex reasoning over long time horizons in a stochastic, partially-observed, procedurally generated setting. To date, no approach, including those based on reinforcement learning, using large pretrained models, using handcoded symbolic agents, imitating expert trajectories or any hybrid method has achieved significant progress towards completing the game. We take a deeper look into the mechanics and interface of the NLE and show that much of the complexity of NetHack is inaccessible due to constraints on the observation and action spaces. We propose a series of modifications and show that they meaningfully improve performance on the NLE."> <meta name="keywords" content="machine-learning, ml, deep-learning, reinforcement-learning, icl# add your own keywords or leave empty"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/revisiting-the-nle/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Revisiting The NetHack Learning Environment",
            "description": "The NetHack Learning Environment (NLE) was proposed as a challenging benchmark to test an agents abilities to perform complex reasoning over long time horizons in a stochastic, partially-observed, procedurally generated setting. To date, no approach, including those based on reinforcement learning, using large pretrained models, using handcoded symbolic agents, imitating expert trajectories or any hybrid method has achieved significant progress towards completing the game. We take a deeper look into the mechanics and interface of the NLE and show that much of the complexity of NetHack is inaccessible due to constraints on the observation and action spaces. We propose a series of modifications and show that they meaningfully improve performance on the NLE.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Revisiting The NetHack Learning Environment</h1> <p>The NetHack Learning Environment (NLE) was proposed as a challenging benchmark to test an agents abilities to perform complex reasoning over long time horizons in a stochastic, partially-observed, procedurally generated setting. To date, no approach, including those based on reinforcement learning, using large pretrained models, using handcoded symbolic agents, imitating expert trajectories or any hybrid method has achieved significant progress towards completing the game. We take a deeper look into the mechanics and interface of the NLE and show that much of the complexity of NetHack is inaccessible due to constraints on the observation and action spaces. We propose a series of modifications and show that they meaningfully improve performance on the NLE.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#tokenization">Tokenization</a> </div> <div> <a href="#interacting-with-menus">Interacting with Menus</a> </div> <div> <a href="#using-inventory-items">Using Inventory Items</a> </div> <div> <a href="#viewing-inventory-items">Viewing Inventory Items</a> </div> <div> <a href="#viewing-player-attributes">Viewing Player Attributes</a> </div> <div> <a href="#measuring-progress">Measuring Progress</a> </div> <div> <a href="#bringing-it-all-together">Bringing it All Together</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>The NetHack Learning Environment (NLE) <d-cite key="kuttler2020nethack"></d-cite>, based on the classic dungeon-crawling game of NetHack, has been proposed as one of the most challenging benchmarks in AI. It is stochastic, long-horizon, partially observed, procedurally generated, and contains hundreds of objects, monsters, dungeon features and other entities which interact in complex ways. Mastering the game of NetHack can require months to years for humans, and approaches including large-scale RL methods<d-cite key="kuttler2020nethack,henaff2025scalable"></d-cite>, frontier LLMs <d-cite key="paglieri2024balrog,klissarov2023motif,klissarov2024maestromotif"></d-cite>, imitating expert trajectories <d-cite key="hambro2022dungeons,piterbarg2023nethack,tuyls2023scaling,wolczyk2024fine"></d-cite>, as well as hardcoded symbolic methods <d-cite key="hambro2022insights"></d-cite> all struggle to advance beyond the earliest game stages, indicating that it constitutes a useful testbed for developing and evaluating AI agents.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/nethack-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/nethack-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/nethack-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/nethack.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>We argue that the current NLE interface is fundamentally limited and makes it intractable or impossible to perform many basic and essential behaviors, largely due to limited observation spaces and action parameterizations. We propose a series of modifications to this setup and validate each change on a custom made environment made using the MiniHack<d-cite key="samvelyan2021minihack"></d-cite> framework. Finally, we show that combining all these modifications improves performance on the NLE when training an RL agent from scratch using Sample Factory PPO as our base implementation.</p> <p>We believe that the NLE is an excellent and unique environment to push the limits of artificial agents, but that much of this complexity has been locked behind the existing interfaces and protocols. We hope that future work on the NLE can use our proposals as a foundation to further their research.</p> <h2 id="tokenization">Tokenization</h2> <p>Textual observations are a vital part of the NLE and being able to properly parse text is needed for any agent that hopes to complete the game. </p> <p>To avoid confusion, since the game is rendered using colored ASCII characters, we make a distinction between <em>glyphs</em>, which form the main screen and represent dungeon features and <em>text</em>, which communicates information in English.</p> <p>Examples of text include:</p> <h3 id="messages">Messages</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/message2-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/message2-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/message2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/message2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Messages give you information about events that have occurred in the game. This includes events induced by the player (e.g. dropping items), events that take place in the players line of sight (e.g. "The hill orc puts on an orcish helm") and events that the player can sense through other means (e.g. "You hear someone counting money"). </div> <h3 id="player-inventory">Player Inventory</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/inventory-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/inventory-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/inventory-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/inventory.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Your inventory consists of all the items you are carrying, represented in text form. </div> <h3 id="menus">Menus</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/menu2-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/menu2-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/menu2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/menu2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Interacting with many parts of NetHack requires navigating menus, which are represented in text form. </div> <p>Existing non-LLM approaches either use the symbolic representation, where the message line is passed through a character level CNN or operate directly on the <code class="language-plaintext highlighter-rouge">tty_chars</code> grid of rendered characters, in which glyphs and texts are conflated.</p> <p>Language modelling orthodoxy tells us that tokenizing text above the character level is preferable, however early experiments with off the shelf tokenizers proved to be too cumbersome and significantly slowed down training. Furthermore, the distribution of text inside NetHack is vastly different from that on which general tokenizers are trained, for instance the words <code class="language-plaintext highlighter-rouge">wand</code>, <code class="language-plaintext highlighter-rouge">potion</code>, <code class="language-plaintext highlighter-rouge">gnome</code> and <code class="language-plaintext highlighter-rouge">uncursed</code> all feature among the top 50 most common words in NetHack. This distributional mismatch motivated us to create a NetHack specific word level tokenizer. We extract the 3000 most frequent words (ignoring punctuation and delimited by spaces) from the message lines of the Dungeons and Data<d-cite key="hambro2022dungeons"></d-cite> offline dataset of human trajectories:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1: you
2: the
3: what
4: to
5: do
6: of
7: in
8: here
9: want
10: an
11: hit
12: your
13: is
14: hear
15: see

...

2986: dwarfs
2987: yowls
2988: ru
2989: lets
2990: pattern
2991: quality
2992: dilithium
2993: elberethel
2994: 115
2995: telefonmann
2996: luckily
2997: ulch
2998: archie
2999: remains
3000: sluggish
</code></pre></div></div> <p>We use this vocabulary to learn embeddings from scratch during training, replacing the CNN on the message line with a bag of words, which was shown to be a competitive representation for NetHack messages<d-cite key="zheng2024online"></d-cite> while being simpler and faster than using a transformer. As well as being used for parsing messages, this tokenizer underpins other proposed changes discussed later in the blog.</p> <h2 id="interacting-with-menus">Interacting with Menus</h2> <p>In-game menus form an important part of NetHack and appear when putting items into or taking items out of containers, picking up from a pile of items, casting spells, enhancing skills and many other cases. Despite their prominence in the game, menus tend to be either completely or partially unobserved in NLE setups that are not language based:</p> <ul> <li>The original symbolic NLE agent does not observe menus at all. This has been noted by the authors in a <a href="https://github.com/facebookresearch/nle/pull/207" rel="external nofollow noopener" target="_blank">GitHub issue</a>.</li> <li>Some setups which operate directly on the rendered <code class="language-plaintext highlighter-rouge">tty_chars</code> only observe a cropped rendering centered around the player <d-cite key="piterbarg2023nethack"></d-cite>. This leads to strange behavior where the menu is only visible (or partially) visible if the agent is near the top right corner of the screen.</li> <li>Other setups that observe the entire <code class="language-plaintext highlighter-rouge">tty_chars</code> will make no distinction between glyphs and text<d-cite key="tuyls2023scaling,wolczyk2024fine"></d-cite>, passing rows of text through a 2D CNN, greatly increasing the difficulty of the learning problem. </li> </ul> <p>These setups greatly complicate the learning problem since, as well as not being able to observe the contents of an opened menu, an agent cannot easily tell whether a menu is even open or not, meaning it may try and act in the world and inadvertently take some actions in an unseen menu it has unwittingly opened.</p> <p>We propose adding the contents of an opened menu directly to the agent’s observation space. We achieve this by extracting the menu from the rendered <code class="language-plaintext highlighter-rouge">tty_chars</code>, noting that all menus are anchored in the bottom left corner by the <code class="language-plaintext highlighter-rouge">"(end)"</code> string, which we use to locate the menu. We then extract all non-header lines from the menu, tokenize them and apply a bag of words.</p> <p>While this change allows the agent to view menus, it is still tricky to learn how to properly interact with them. Each menu option is labelled by a letter, which is used to select it. Instead of forcing the agent to learn this mapping, we give the agent an augmented action space which allows it to choose from <code class="language-plaintext highlighter-rouge">menu_option_1, menu_option_2, ..., menu_option_n</code>. We extract the letter label for each menu option from the <code class="language-plaintext highlighter-rouge">tty_chars</code> and then convert menu option actions to their respective primitive actions, which are then fed into the NLE.</p> <p>To test and showcase this change, we create a simple MiniHack environment which contains a pile of two gemstones stacked in a randomized order. The agent receives a positive reward if it picks up only the gem named <code class="language-plaintext highlighter-rouge">pick me up</code>, which requires it to understand and then interact with a menu.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack_in_game-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack_in_game-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack_in_game-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack_in_game.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The results show that the augmented observation and action space allow the agent to properly use the in-game menu system.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_stack.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="using-inventory-items">Using Inventory Items</h2> <p>Another menu-like component of NetHack is that upon initiating certain actions, the game will prompt the user for which item they wish to use from their inventory, using the message line rather than opening an explicit menu. For instance, initiating the throw action by pressing the letter <code class="language-plaintext highlighter-rouge">t</code>, will induce the following message.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/what_do_you_want_to_throw-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/what_do_you_want_to_throw-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/what_do_you_want_to_throw-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/what_do_you_want_to_throw.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The string <code class="language-plaintext highlighter-rouge">abh</code> refers to the items in the players inventory that are capable of being thrown, indexed by those respective letters.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/weapons-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/weapons-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/weapons-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/weapons.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>To make a decision on which item to use, the agent must cross reference the letters from both the message string and from the inventory. Unlike with menus, this is technically feasible with existing setups, but it is a very challenging learning problem for the agent to draw these connections.</p> <p>Similar to the menu system, we propose augmenting both the observation and action space of the agent to make this problem tractable. When the agent is confronted by a message to use an item from its inventory, the letters in the message are parsed and automatically cross-referenced with the corresponding items in the agent’s inventory. Each item is then observed by the agent as a bag of words, and the agent can pick which item to use with the same augmented action space introduced for navigating menus.</p> <p>We modify the previous MiniHack environment so that the agent starts with multiple gems in its inventory. It must drop only the gem named <code class="language-plaintext highlighter-rouge">put me down</code> to receive a positive reward.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop_in_game-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop_in_game-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop_in_game-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop_in_game.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The results show that the augmented inventory selection observation and action space allow the agent to properly select items from its inventory.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/gem_drop.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="viewing-inventory-items">Viewing Inventory Items</h2> <p>As well as using inventory items, it is useful for the agent to be able to view the items in its inventory at all times, a feature which is lacking from many existing NLE agents. Depending on the rendering system a player uses, NetHack can either be played with the inventory visible at all times (for instance by enabling <code class="language-plaintext highlighter-rouge">curses</code> rendering) or, more commonly, the inventory must be viewed by pressing <code class="language-plaintext highlighter-rouge">i</code>. Existing approaches do not tend to include the inventory in the observation, meaning the agent must press <code class="language-plaintext highlighter-rouge">i</code> to open view its inventory. However, as discussed in previous sections, approaches based off the original symbolic architecture will not be able to see the opened menu, while those that operate directly on the <code class="language-plaintext highlighter-rouge">tty_chars</code> will either see a partial/cropped inventory, or will attempt to parse it by passing the rows through a 2D CNN.</p> <p>We make use of the <code class="language-plaintext highlighter-rouge">inv_strs</code> observation already made available by the NLE and tokenize each element with a bag of words. We then pass each entry through an MLP before summing the embedding again. This gives the agent a permutation invariant view of the items in its inventory.</p> <p>To demonstrate this, we create a MiniHack environment where the agent starts wearing a <code class="language-plaintext highlighter-rouge">ring of fire resistance</code> or a <code class="language-plaintext highlighter-rouge">ring of cold resistance</code>. The agent has the choice to fight either fire-based or ice-based enemies and its success will depend on which ring the agent starts with, making the ability to read its inventory essential.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv_in_game-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv_in_game-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv_in_game-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv_in_game.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The results show that the augmented inventory view allows the agent to understand its inventory.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/ring_inv.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="viewing-player-attributes">Viewing Player Attributes</h2> <p>When beginning a new game of NetHack, the player can choose the race, role , gender and alignment of their character. This choice has an enormous impact on the game, deciding the players starting inventory, attributes, affinity for different abilities and will affect the generation of some dungeons, as well as determining which monsters are hostile or neutral towards the player. The strategies and difficulty of different roles varely immensely.</p> <p>However, as <a href="https://github.com/facebookresearch/nle/pull/207" rel="external nofollow noopener" target="_blank">noted by the original NLE authors</a>, the agent can struggle to view these essential characteristics and must resort to inferring them from its inventory and attributes. With the agent now able to read menus, it theoretically could invoke the <code class="language-plaintext highlighter-rouge">#attributes</code> action to view this information, but this again seems extremely difficult to expect an agent to learn. Instead, we propose a small modification where the <code class="language-plaintext highlighter-rouge">#attributes</code> action is immediately invoked upon a new episode, with the role/race/alignement information extracted, processed and stored, then being fed to the agents observation as an additional symbolic key for the rest of the episode.</p> <h2 id="measuring-progress">Measuring Progress</h2> <p>A unique aspect of the NLE is that it is not even entirely clear what metric should be used to measure progress. It is <a href="https://github.com/facebookresearch/nle/issues/278" rel="external nofollow noopener" target="_blank">generally agreed</a> that the true underlying objective is to <em>ascend</em> to demi-godness and thus beat the game, but this has never been achieved by a non-human agent, so some intermediate measure of progress must be used in the meantime.</p> <p>The original NetHack challenge used in-game score for the competition, and this has been largely used in work since. However, as noted in prior work, this has significant issues, as maximizing score tends to lead to agents that don’t make much progress towards ascension. Score can be achieved by killing enemies, which will endlessly spawn on every level of the dungeon. Rather than venturing into lower dungeon levels and risking death, many score-maximizing agents will instead camp on the easy dungeon levels, racking up high scores but not making any progress towards beating the game. Conversely, it is a common strategy for human players try to kill as few enemies as possible to keep their experience level low and reduce the chance of high level enemies appearing later in the game. Finally, and perhaps most damningly, an optimal agent that maximizes score will never beat the game, as there is an unbounded amount of score to be achieved.</p> <p>BALROG proposed a data driven approach to measuring progress, by looking at the agents experience level and dungeon floor and relating this to the probability of an equivalently placed player in Dungeons and Data beating the game. While this approach is principled and useful for evaluation, it is too sparse to be used as a reward signal for a reinforcement learning agent.</p> <p>We instead propose using the <em>scout</em> measure, which increases every time the player observes a new tile, as the metric for progress in the NLE. Qualitatively, we observe an agent that maximises scout making better progress in the game, reaching significantly further levels and not hanging around in the early stages of the game. Crucially, the maximisation of the scout metric should in theory lead to an agent that explores the entire dungeon and enters the Astral Plane, where it can ascend. If an agent ever gets this far, a simple flat bonus for ascension would lead to an MDP where the reward maximising agent will ascend, unlike with score, since the scout reward is finite.</p> <h2 id="bringing-it-all-together">Bringing it All Together</h2> <p>Having proposed a number of modifications to the NLE interface and validating them on toy MiniHack environments, we see that combining all these proposed changes leads to a modest improvment in scout score on the NLE when running with PPO.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/2026/assets/img/2026-04-27-revisiting-the-nle/main_result-480.webp 480w,/2026/assets/img/2026-04-27-revisiting-the-nle/main_result-800.webp 800w,/2026/assets/img/2026-04-27-revisiting-the-nle/main_result-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/2026/assets/img/2026-04-27-revisiting-the-nle/main_result.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="conclusion">Conclusion</h2> <p>We have identified a number of deficiencies in existing implementations that aim to solve the NLE, with large parts of the game either impossible or intractable to interact with. We have proposed a number of changes to the observation space, action parameterization and metrics for the NLE. We have then gone on to show that, when these changes are brought together, we can learn an agent with tabula rasa RL on the NLE that shows meaningful improvement over the baseline. We open source our code and hope that this work can serve as a foundation for future work on the NLE.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-revisiting-the-nle.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/fairness-audits/">Fairness Audits as Theater: When Metrics Mask Structural Harm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/beyond-attention-as-graph/">Beyond Attention as a Graph</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/attention-sinks-graph-perspective/">Attention Sinks from the Graph Perspective</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/zero-rewards/">What Can You Do When You Have Zero Rewards During RL?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/witness-problem/">The Witness Problem in Multi-Agent Cooperation</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>