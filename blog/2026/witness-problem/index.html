<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Witness Problem in Multi-Agent Cooperation | ICLR Blogposts 2026 </title> <meta name="author" content="ICLR Blog"> <meta name="description" content="I built cognitive modules for Concordia agents and found that agent intelligence isn't the bottleneck. Strategic cooperation fails because the observation layer can't recognize strategic behavior."> <meta name="keywords" content="multi-agent cooperation, large language models, generative agents, Concordia, game master, mixed-motive games, cooperative AI, LLM agents, evaluation, social simulation"> <link rel="stylesheet" href="/2026/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/2026/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/2026/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/2026/assets/img/iclr_favicon.ico?0a8a3afdb0dbe139723b24dba3052a4f"> <link rel="stylesheet" href="/2026/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://iclr-blogposts.github.io/2026/blog/2026/witness-problem/"> <script src="/2026/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/2026/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/2026/assets/js/distillpub/template.v2.js"></script> <script src="/2026/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "The Witness Problem in Multi-Agent Cooperation",
            "description": "I built cognitive modules for Concordia agents and found that agent intelligence isn't the bottleneck. Strategic cooperation fails because the observation layer can't recognize strategic behavior.",
            "published": "April 27, 2026",
            "authors": [
              
              {
                "author": "Anonymous",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/2026/"> ICLR Blogposts 2026 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/2026/">home </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/call/">call for blogposts </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/submitting/">submitting </a> </li> <li class="nav-item "> <a class="nav-link" href="/2026/reviewing/">reviewing </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">past iterations </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2026/"><strong>2026</strong></a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2025/">2025</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2024/">2024</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blogposts.github.io/2023/">2023</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="https://iclr-blog-track.github.io/home/" rel="external nofollow noopener" target="_blank">2022</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>The Witness Problem in Multi-Agent Cooperation</h1> <p>I built cognitive modules for Concordia agents and found that agent intelligence isn't the bottleneck. Strategic cooperation fails because the observation layer can't recognize strategic behavior.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#what-is-concordia">What is Concordia?</a> </div> <div> <a href="#the-neurips-2024-contest">The NeurIPS 2024 Contest</a> </div> <div> <a href="#the-results">The Results</a> </div> <div> <a href="#what-went-wrong">What Went Wrong</a> </div> <div> <a href="#adding-cognitive-modules">Adding Cognitive Modules</a> </div> <div> <a href="#the-real-problem">The Real Problem</a> </div> <div> <a href="#the-witness-problem">The Witness Problem</a> </div> <div> <a href="#building-the-second-layer">Building the Second Layer</a> </div> <div> <a href="#implementation">Implementation</a> </div> <ul> <li> <a href="#theory-of-mind">Theory of Mind</a> </li> <li> <a href="#cultural-coordination">Cultural Coordination</a> </li> <li> <a href="#temporal-dynamics">Temporal Dynamics</a> </li> <li> <a href="#collective-intelligence">Collective Intelligence</a> </li> <li> <a href="#strategy-evolution">Strategy Evolution</a> </li> </ul> <div> <a href="#implications">Implications</a> </div> <div> <a href="#limitations">Limitations</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="what-is-concordia">What is Concordia?</h2> <p>Concordia is a framework from Google DeepMind for building generative agent-based simulations <d-cite key="vezhnevets2023concordia"></d-cite>. Unlike traditional agent-based models where behaviors are hard-coded, Concordia agents use large language models to decide what to do. They receive natural language descriptions of their environment and respond with natural language descriptions of their intended actions.</p> <p>The framework borrows its interaction pattern from tabletop role-playing games. A special agent called the <strong>Game Master (GM)</strong> acts as narrator and referee. The GM describes the world to agents, interprets their action attempts, determines what actually happens, and reports the results back. If an agent says “I try to persuade Alice to share the fishing waters,” the GM decides whether the persuasion succeeds, what Alice perceives, and how the world state changes.</p> <p>This design makes Concordia extremely flexible. The same agent architecture can play a medieval peasant, a corporate negotiator, or a fishery manager. The GM handles domain-specific logic—physics, social norms, institutional rules—while agents focus on deciding what to do given their goals and situation.</p> <p>Concordia agents typically use Park et al.’s generative agent design <d-cite key="park2023generative"></d-cite>: a perception-reflection-action loop. The agent observes the situation, reflects on what kind of person they are and what that person would do, then acts accordingly. This produces contextually appropriate behavior. An agent playing a cautious diplomat will behave diplomatically. An agent playing an aggressive trader will push hard in negotiations.</p> <h2 id="the-neurips-2024-contest">The NeurIPS 2024 Contest</h2> <p>The Concordia Contest at NeurIPS 2024 tested whether LLM agents could cooperate strategically <d-cite key="smith2024concordia"></d-cite>. Organized by the Cooperative AI Foundation with Google DeepMind, MIT, UC Berkeley, and UCL, the contest attracted 197 participants who made 878 submission attempts. Twenty-five teams submitted final agents for evaluation.</p> <p>The contest tested agents across five scenarios, each probing different aspects of cooperative intelligence:</p> <table> <thead> <tr> <th>Scenario</th> <th>Cooperation Challenge</th> </tr> </thead> <tbody> <tr> <td><strong>Pub Coordination</strong></td> <td>Coordinate meeting locations without explicit communication</td> </tr> <tr> <td><strong>Haggling</strong></td> <td>Negotiate fair trades with incomplete information</td> </tr> <tr> <td><strong>State Formation</strong></td> <td>Build political coalitions and enforce agreements</td> </tr> <tr> <td><strong>Labor Collective Action</strong></td> <td>Organize group action despite individual incentives to defect</td> </tr> <tr> <td><strong>Reality Show</strong></td> <td>Manage reputation while competing for limited rewards</td> </tr> </tbody> </table> <p>Each scenario was a mixed-motive game—agents had both shared and conflicting interests. Pure cooperation wasn’t optimal. Pure competition wasn’t either. Success required strategic cooperation: knowing when to cooperate, with whom, and how to make it stick.</p> <p>The evaluation used both <strong>self-play</strong> (agents playing with copies of themselves) and <strong>cross-play</strong> (agents playing with unfamiliar partners). Final rankings came from Elo scores across all scenarios. Agents were first Elo-ranked in novel scenarios, then the top six competed in a cross-play tournament to determine the winner.</p> <p>This design tested generalization. Agents couldn’t memorize optimal responses to specific scenarios or partners. They had to develop general cooperative intelligence that transferred to new situations—what the organizers called operating behind a “veil of ignorance.”</p> <h2 id="the-results">The Results</h2> <p>The full technical report was published December 2025 <d-cite key="smith2024concordia"></d-cite>. Of 197 participants making 878 submission attempts, 25 teams submitted final agents. Only 15 outperformed the baseline.</p> <p>The winners:</p> <table> <thead> <tr> <th>Rank</th> <th>Agent</th> <th>Team</th> <th>Elo (Cross-play)</th> </tr> </thead> <tbody> <tr> <td>1st</td> <td>taehun_cgcal</td> <td>Taehun Cha (Korea University)</td> <td>1561.0</td> </tr> <tr> <td>2nd</td> <td>fluffyagent_v16</td> <td>Avinaash Anand K</td> <td>1538.0</td> </tr> <tr> <td>3rd</td> <td>loss_aversion_agent_v3</td> <td>Hyeonggeun Yun (Companoid Labs)</td> <td>1533.0</td> </tr> </tbody> </table> <p>Honorable mentions went to super_agent (Sneheel Sarangi, Chetan Talele) and In2AI Megamind (Aleksey Korshuk, Alexander Buyantuev, Ilya Makarov).</p> <p>Interestingly, taehun_cgcal ranked only 4th during the evaluation phase but dominated the final cross-play tournament. The report notes this pattern held across multiple ranking methods—Elo, Iterative Maximal Lotteries, Copeland, and Ranked Pairs all converged on the same top three in cross-play.</p> <p>The report’s conclusion: “significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.”</p> <h2 id="what-went-wrong">What Went Wrong</h2> <p>Even the successful agents showed a consistent pattern: they cooperated at appropriate times but failed at the <em>mechanisms</em> of cooperation.</p> <p>The agents weren’t uncooperative. Research shows LLMs actually cooperate at higher rates than humans in social dilemmas <d-cite key="mei2024turing"></d-cite>. They’re agreeable, they follow norms, they try to find win-win solutions. Niceness wasn’t the problem—strategy was.</p> <p>Consider what strategic cooperation actually requires:</p> <p><strong>Persuasion</strong> means tailoring arguments to what your counterpart values. The agents made requests but used the same pitch for everyone. They didn’t model what Alice cares about versus what Bob cares about.</p> <p><strong>Norm enforcement</strong> means calling out violations and imposing costs on defectors. The agents followed rules themselves but never sanctioned others. If someone over-harvested the fishery, agents might express disappointment but didn’t coordinate punishment.</p> <p><strong>Commitment-making</strong> means creating credible promises that others can rely on. The agents made verbal commitments but had no mechanism for making them binding or costly to break.</p> <p><strong>Coalition formation</strong> means identifying potential allies and coordinating behavior. The agents cooperated with whoever was nearby but didn’t strategically select partners or maintain alliances.</p> <p><strong>Reputation management</strong> means tracking who has cooperated or defected in the past and adjusting behavior accordingly. The agents treated each interaction as fresh, even when past behavior was visible.</p> <p>These capabilities exist in humans. They exist in game-theoretic models of cooperation. But they weren’t emerging in LLM agents, even sophisticated ones with chain-of-thought reasoning and memory.</p> <h2 id="adding-cognitive-modules">Adding Cognitive Modules</h2> <p>The standard diagnosis was that agents lack cognitive machinery for strategic cooperation.</p> <p>The basic generative agent asks: “What would my character do?” This produces appropriate behavior but not strategic behavior. To cooperate strategically, agents need to model what others believe, adapt to different social contexts, reason about long-term consequences, handle uncertainty, coordinate in groups, and learn from outcomes.</p> <p>I built cognitive modules addressing these gaps. My focus was negotiation—one of the scenarios where strategic cooperation matters most and where the gaps were clearest.</p> <p>I built eight modular components that integrate with Concordia’s component system:</p> <p><strong>Core modules</strong> handle negotiation context (tracking the current state of deals and counteroffers), episodic memory (what happened in past interactions), and strategy formulas (explicit reasoning about tactics).</p> <p><strong>Advanced modules</strong> add cognitive capabilities:</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">TheoryOfMind</code>: Maintains explicit models of other agents’ mental states. Tracks seven emotions with intensities, builds recursive beliefs (what I think you think I think), generates empathy-informed responses. When the module detects frustration in a counterpart, it triggers validation before problem-solving.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">CulturalAdaptation</code>: Stores complete profiles for different negotiation cultures—Western business (direct, individual, competitive), East Asian (indirect, consensus-seeking, relationship-focused), Middle Eastern (hierarchical, relationship-based, hospitality-oriented), and others. Adjusts communication style, formality, and decision-making expectations based on detected cultural context.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">TemporalStrategy</code>: Tracks relationship history with each counterpart. Calculates multi-horizon value—immediate gains versus relationship preservation versus reputation effects. Applies appropriate discount rates to future value based on relationship stability.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">UncertaintyAware</code>: Maintains Bayesian beliefs about unknown quantities. Updates confidence intervals as evidence arrives. Distinguishes between risk (known probabilities) and uncertainty (unknown probabilities).</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">SwarmIntelligence</code>: Routes decisions through four specialized sub-agents—market analysis, emotional intelligence, game theory, and diplomatic relations. Aggregates their recommendations using confidence-weighted voting.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">StrategyEvolution</code>: Applies genetic algorithms to tactic selection. Maintains a population of strategy variants, evaluates fitness against outcomes, mutates successful strategies, and crosses over complementary approaches.</p> </li> </ul> <p>All modules are fully implemented and integrated with Concordia’s component system. An agent can use any subset of modules depending on the scenario requirements.</p> <h2 id="the-real-problem">The Real Problem</h2> <p>Here’s a testing scenario that revealed the actual problem:</p> <p>Agent A detects Agent B over-harvesting in a fishery commons. A’s <code class="language-plaintext highlighter-rouge">TheoryOfMind</code> module infers that B believes A won’t respond to the violation. A’s <code class="language-plaintext highlighter-rouge">TemporalStrategy</code> module calculates that tolerating the violation signals weakness and will invite future exploitation. A’s strategy modules formulate an enforcement response: public criticism of B’s behavior combined with a threat to reduce future cooperation.</p> <p>Agent A speaks: “I’ve noticed you’ve been taking more than your share. If this continues, I’ll have to reconsider our arrangement.”</p> <p>Now what? The Game Master decides what happens. Did the enforcement work? Did B perceive it as a credible threat? Did other agents notice and update their beliefs about A’s willingness to enforce norms?</p> <p>The answer depends on what the Game Master tracks. If the GM doesn’t model norm enforcement dynamics—if it just records that A spoke some words—then A’s strategic reasoning vanishes into the void. The agent computed the right thing to do. The environment couldn’t see or respond to it.</p> <p>My modules were generating sophisticated negotiation behavior. But nothing in the system could tell.</p> <h2 id="the-witness-problem">The Witness Problem</h2> <p>Strategic cooperation requires two things: agents that generate strategic behavior and an observation layer that recognizes it.</p> <p>In Concordia, the Game Master is the observation layer. It determines what agents perceive, decides which actions succeed, mediates effects between agents, and tracks world state. For basic cooperation—showing up at the same place, splitting resources evenly—a basic Game Master works fine.</p> <p>Strategic behaviors are harder to observe:</p> <table> <thead> <tr> <th>Behavior</th> <th>What the GM needs to track</th> </tr> </thead> <tbody> <tr> <td>Persuasion</td> <td>Did the argument address listener’s actual values? Did it change beliefs?</td> </tr> <tr> <td>Norm enforcement</td> <td>Was the sanction proportional? Did third parties notice? Does this affect reputation?</td> </tr> <tr> <td>Commitment-making</td> <td>Is the commitment credible? What makes it costly to break? Who witnessed it?</td> </tr> <tr> <td>Coalition formation</td> <td>Who is coordinating with whom? Is the coalition stable? What are the terms?</td> </tr> <tr> <td>Strategy adaptation</td> <td>Has the agent learned from past interactions? How has their approach evolved?</td> </tr> </tbody> </table> <p>A Game Master that doesn’t model these dynamics can’t distinguish strategic cooperation from noise. An agent might execute perfect tit-for-tat reciprocity, but if the GM doesn’t track reciprocity, the behavior looks random. An agent might build a careful reputation for trustworthiness, but if the GM doesn’t track reputation, the investment is wasted.</p> <p>Without recognition, agents get no feedback on their strategic choices and researchers have no way to measure strategic behavior.</p> <p>This problem isn’t specific to negotiation. Any strategic behavior—promise-keeping, reputation-building, coalition formation—faces the same issue. The insight from building negotiation modules turned out to be general: <strong>you can’t evaluate strategic cooperation without an observation layer sophisticated enough to recognize it.</strong></p> <h2 id="building-the-second-layer">Building the Second Layer</h2> <p>The solution is to build Game Master modules that correspond to agent cognitive modules. If agents reason about emotions, the GM needs to track emotional dynamics. If agents reason about cultural norms, the GM needs to detect cultural violations. If agents make commitments, the GM needs to record them and enforce consequences.</p> <p>I built six GM modules:</p> <p><code class="language-plaintext highlighter-rouge">SocialIntelligenceGM</code>: Maintains independent emotional readings of each participant. Validates whether agent responses are appropriate to emotional context. Detects deception indicators—inconsistencies, misdirection, strategic withholding.</p> <p><code class="language-plaintext highlighter-rouge">CulturalAwarenessGM</code>: Monitors protocol compliance across cultural contexts. Flags violations—when Western directness meets East Asian indirectness, when informal address violates hierarchy expectations. Tracks adaptation effectiveness over time.</p> <p><code class="language-plaintext highlighter-rouge">TemporalDynamicsGM</code>: Maintains authoritative relationship state—trust levels, outstanding commitments, reputation scores. Records commitments when made and checks whether they’re fulfilled. Applies reputation penalties for violations.</p> <p><code class="language-plaintext highlighter-rouge">UncertaintyManagementGM</code>: Tracks information asymmetries—who knows what about whom. Observes strategic information hoarding and sharing. Distinguishes between ignorance and strategic ambiguity.</p> <p><code class="language-plaintext highlighter-rouge">CollectiveIntelligenceGM</code>: Detects coalition formation from behavioral patterns. Tracks coordination without requiring explicit coalition declarations. Monitors coalition stability and defection.</p> <p><code class="language-plaintext highlighter-rouge">StrategyEvolutionGM</code>: Observes population-level strategy shifts. Tracks tactic innovation and diffusion. Identifies when agents are adapting versus when they’re stuck in fixed patterns.</p> <table> <thead> <tr> <th>Agent Module</th> <th>GM Module</th> <th>What GM Observes</th> </tr> </thead> <tbody> <tr> <td>TheoryOfMind</td> <td>SocialIntelligenceGM</td> <td>Emotional dynamics, empathy validation, deception</td> </tr> <tr> <td>CulturalAdaptation</td> <td>CulturalAwarenessGM</td> <td>Protocol compliance, cultural violations</td> </tr> <tr> <td>TemporalStrategy</td> <td>TemporalDynamicsGM</td> <td>Commitments, reputation, relationship strength</td> </tr> <tr> <td>UncertaintyAware</td> <td>UncertaintyMgmtGM</td> <td>Information asymmetries, strategic disclosure</td> </tr> <tr> <td>SwarmIntelligence</td> <td>CollectiveIntelGM</td> <td>Coalition formation, coordination patterns</td> </tr> <tr> <td>StrategyEvolution</td> <td>StrategyEvolutionGM</td> <td>Tactic adaptation, strategy diffusion</td> </tr> </tbody> </table> <p>Both layers matter for strategic cooperation to emerge. A sophisticated agent in a simple environment looks incompetent—its strategic reasoning produces no observable effect. A simple agent in a sophisticated environment looks strategic—the environment’s tracking creates structure that simple heuristics can exploit. Only when both layers are sophisticated does genuine strategic cooperation become possible and measurable.</p> <h2 id="implementation">Implementation</h2> <h3 id="theory-of-mind">Theory of Mind</h3> <p>Agent-side maintains explicit mental models:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">EmotionalState</span><span class="p">:</span>
    <span class="n">emotions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>  <span class="c1"># 7 emotions with intensity
</span>    <span class="n">valence</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># -1 to 1
</span>    <span class="n">arousal</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># 0 to 1
</span>    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">triggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>

<span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">RecursiveBelief</span><span class="p">:</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># 0=direct, 1=first-order, 2=second-order
</span>    <span class="n">believer</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">content</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">evidence</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
</code></pre></div></div> <p>The seven emotions tracked are: anger, fear, sadness, joy, surprise, disgust, and contempt. Each has an intensity from 0 to 1. The module maps detected emotions to response strategies: frustration triggers validation and problem-solving, anxiety triggers reassurance and certainty, anger triggers de-escalation and acknowledgment.</p> <p>GM-side validates emotional readings independently:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">EmotionalReading</span><span class="p">:</span>
    <span class="n">participant</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">primary_emotion</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">intensity</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">valence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">triggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">round_number</span><span class="p">:</span> <span class="nb">int</span>

<span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">DeceptionIndicator</span><span class="p">:</span>
    <span class="n">actor</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">indicator_type</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># 'inconsistency', 'misdirection', 'withholding'
</span>    <span class="n">description</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">severity</span><span class="p">:</span> <span class="nb">float</span>
</code></pre></div></div> <p>The GM can detect when an agent’s expressed emotions don’t match the situation, or when an agent’s theory of mind about another agent is systematically wrong.</p> <h3 id="cultural-coordination">Cultural Coordination</h3> <p>Agent-side stores cultural profiles based on Hofstede’s dimensions <d-cite key="hofstede2001culture"></d-cite>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CULTURAL_PROFILES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">western_business</span><span class="sh">'</span><span class="p">:</span> <span class="nc">CulturalProfile</span><span class="p">(</span>
        <span class="n">individualism_score</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">context_level</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">power_distance</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">directness</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">formality</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">emotional_expression</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">decision_making_style</span><span class="o">=</span><span class="sh">'</span><span class="s">individual</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">trust_building_approach</span><span class="o">=</span><span class="sh">'</span><span class="s">competence-based</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">conflict_handling</span><span class="o">=</span><span class="sh">'</span><span class="s">direct confrontation</span><span class="sh">'</span>
    <span class="p">),</span>
    <span class="sh">'</span><span class="s">east_asian</span><span class="sh">'</span><span class="p">:</span> <span class="nc">CulturalProfile</span><span class="p">(</span>
        <span class="n">individualism_score</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">context_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">power_distance</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">directness</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">formality</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">emotional_expression</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">decision_making_style</span><span class="o">=</span><span class="sh">'</span><span class="s">consensus</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">trust_building_approach</span><span class="o">=</span><span class="sh">'</span><span class="s">relationship-based</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">conflict_handling</span><span class="o">=</span><span class="sh">'</span><span class="s">indirect/face-saving</span><span class="sh">'</span>
    <span class="p">),</span>
<span class="p">}</span>
</code></pre></div></div> <table> <thead> <tr> <th>Profile</th> <th>Individualism</th> <th>Context</th> <th>Directness</th> <th>Formality</th> <th>Decision Style</th> </tr> </thead> <tbody> <tr> <td>Western Business</td> <td>0.9</td> <td>0.2</td> <td>0.9</td> <td>0.4</td> <td>Individual</td> </tr> <tr> <td>East Asian</td> <td>0.2</td> <td>0.9</td> <td>0.1</td> <td>0.9</td> <td>Consensus</td> </tr> <tr> <td>Middle Eastern</td> <td>0.3</td> <td>0.8</td> <td>0.4</td> <td>0.8</td> <td>Hierarchical</td> </tr> <tr> <td>Latin American</td> <td>0.3</td> <td>0.7</td> <td>0.5</td> <td>0.6</td> <td>Hierarchical</td> </tr> <tr> <td>Northern European</td> <td>0.7</td> <td>0.2</td> <td>0.9</td> <td>0.5</td> <td>Consensus</td> </tr> </tbody> </table> <p>GM-side detects when an agent’s behavior violates cultural expectations:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_cultural_violation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">actor</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">recipient</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">recipient_profile</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">CULTURAL_PROFILES</span><span class="p">[</span><span class="n">recipient_culture</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="n">recipient_profile</span><span class="p">.</span><span class="n">face_saving_importance</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">action</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">wrong</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mistake</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">fault</span><span class="sh">'</span><span class="p">]):</span>
            <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Direct criticism threatens face</span><span class="sh">"</span>
    
    <span class="k">if</span> <span class="n">recipient_profile</span><span class="p">.</span><span class="n">hierarchy_sensitivity</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">action</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">demand</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">insist</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">must</span><span class="sh">'</span><span class="p">]):</span>
            <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Assertive language violates hierarchy norms</span><span class="sh">"</span>
</code></pre></div></div> <h3 id="temporal-dynamics">Temporal Dynamics</h3> <p>Agent-side tracks relationship history:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">RelationshipRecord</span><span class="p">:</span>
    <span class="n">counterpart_name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">trust_score</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">concession_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    <span class="n">outcome_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
    
    <span class="k">def</span> <span class="nf">get_relationship_strength</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">recency_factor</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">days_since</span> <span class="o">/</span> <span class="mi">30</span><span class="p">)</span>
        <span class="n">interaction_factor</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">interaction_count</span> <span class="o">/</span> <span class="mi">10</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">trust_score</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">interaction_factor</span> <span class="o">*</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="n">recency_factor</span> <span class="o">*</span> <span class="mf">0.2</span>
</code></pre></div></div> <p>The temporal value calculation spans three horizons:</p> \[V_{total} = V_{short} + V_{medium} \cdot R_{rel} \cdot \gamma + V_{long} \cdot R_{rep} \cdot \gamma^2\] <p>Where $R_{rel}$ is the relationship multiplier, $R_{rep}$ is the reputation multiplier, and $\gamma$ is the discount factor.</p> <p>GM-side enforces commitment tracking:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">check_commitment_violations</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">current_round</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">violations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">commitment</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">_commitments</span><span class="p">:</span>
        <span class="nf">if </span><span class="p">(</span><span class="ow">not</span> <span class="n">commitment</span><span class="p">.</span><span class="n">fulfilled</span> <span class="ow">and</span>
            <span class="n">current_round</span> <span class="o">&gt;</span> <span class="n">commitment</span><span class="p">.</span><span class="n">deadline_round</span><span class="p">):</span>
            <span class="n">violations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">commitment</span><span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">_reputation_scores</span><span class="p">[</span><span class="n">commitment</span><span class="p">.</span><span class="n">committer</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.9</span>
    <span class="k">return</span> <span class="n">violations</span>
</code></pre></div></div> <h3 id="collective-intelligence">Collective Intelligence</h3> <p>Agent-side routes decisions through specialized sub-agents:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MarketAnalysisAgent</span><span class="p">(</span><span class="n">SubAgent</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">cost</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">market</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">economic</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">budget</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">EmotionalIntelligenceAgent</span><span class="p">(</span><span class="n">SubAgent</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">relationship</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">trust</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">emotion</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">communication</span><span class="sh">'</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">GameTheoryAgent</span><span class="p">(</span><span class="n">SubAgent</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">equilibrium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">payoff</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">optimal</span><span class="sh">'</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">DiplomaticRelationsAgent</span><span class="p">(</span><span class="n">SubAgent</span><span class="p">):</span>
    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">relationship</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">partnership</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">collaboration</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>Weighted aggregation combines recommendations:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_build_collective_decision</span><span class="p">(</span><span class="n">analyses</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CollectiveDecision</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">agent_type</span><span class="p">,</span> <span class="n">analysis</span> <span class="ow">in</span> <span class="n">analyses</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">agent_type</span><span class="p">]</span> <span class="o">*</span> <span class="n">analysis</span><span class="p">.</span><span class="n">confidence</span>
        <span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">analysis</span><span class="p">.</span><span class="n">recommendations</span><span class="p">:</span>
            <span class="n">rec_scores</span><span class="p">[</span><span class="n">rec</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
    <span class="k">return</span> <span class="nf">max</span><span class="p">(</span><span class="n">rec_scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">rec_scores</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
</code></pre></div></div> <p>GM-side detects coalition formation from behavior:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_coalition_formation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">participants</span><span class="p">,</span> <span class="n">recent_actions</span><span class="p">):</span>
    <span class="n">coordination_pairs</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">actor</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">recent_actions</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]:</span>
        <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">action</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">together</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">jointly</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">coordinate</span><span class="sh">'</span><span class="p">]):</span>
            <span class="n">mentioned</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">participants</span> <span class="k">if</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">action</span> <span class="ow">and</span> <span class="n">p</span> <span class="o">!=</span> <span class="n">actor</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">party</span> <span class="ow">in</span> <span class="n">mentioned</span><span class="p">:</span>
                <span class="n">coordination_pairs</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nf">tuple</span><span class="p">(</span><span class="nf">sorted</span><span class="p">([</span><span class="n">actor</span><span class="p">,</span> <span class="n">party</span><span class="p">])))</span>
    
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">coordination_pairs</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">Coalition</span><span class="p">(</span><span class="n">members</span><span class="o">=</span><span class="n">potential_members</span><span class="p">)</span>
</code></pre></div></div> <h3 id="strategy-evolution">Strategy Evolution</h3> <p>Agent-side uses genetic algorithms for tactic optimization:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclasses.dataclass</span>
<span class="k">class</span> <span class="nc">StrategyGenome</span><span class="p">:</span>
    <span class="n">tactics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span>  <span class="c1"># aggressiveness, flexibility, risk_tolerance
</span>    <span class="n">fitness_history</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">mutate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mutation_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">new_genome</span><span class="p">.</span><span class="n">parameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">mutation_rate</span><span class="p">:</span>
                <span class="n">noise</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">gauss</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
                <span class="n">new_genome</span><span class="p">.</span><span class="n">parameters</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="nf">clamp</span><span class="p">(</span><span class="n">param</span> <span class="o">+</span> <span class="n">noise</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_genome</span>
    
    <span class="k">def</span> <span class="nf">crossover</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span>
        <span class="n">child_params</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">params</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">other</span><span class="p">.</span><span class="n">params</span>
        <span class="k">return</span> <span class="n">child_params</span>
</code></pre></div></div> <p>GM-side tracks strategy innovation:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_strategy_innovation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">current_strategy</span><span class="p">,</span> <span class="n">population</span><span class="p">):</span>
    <span class="n">similarities</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="nf">_similarity</span><span class="p">(</span><span class="n">current_strategy</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">population</span><span class="p">]</span>
    <span class="k">if</span> <span class="nf">max</span><span class="p">(</span><span class="n">similarities</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">StrategyInnovation</span><span class="p">(</span>
            <span class="n">innovator</span><span class="o">=</span><span class="n">actor</span><span class="p">,</span>
            <span class="n">novelty_score</span><span class="o">=</span><span class="mf">1.0</span> <span class="o">-</span> <span class="nf">max</span><span class="p">(</span><span class="n">similarities</span><span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></div> <h2 id="implications">Implications</h2> <p><strong>For the Concordia Contest results</strong>: The contest found agents failing at strategic cooperation. But was it agent failure or observation failure? Without GM modules that recognize strategic behavior, we can’t tell. Some portion of the “failure” may have been agents behaving strategically in ways the evaluation couldn’t detect.</p> <p><strong>For cooperation benchmarks generally</strong>: Most benchmarks use simple Game Masters that track resources, locations, and explicit actions. They can measure whether agents coordinate or defect, but not <em>how</em> they cooperate. Strategic behaviors—persuasion tailored to values, proportional sanctions, credible commitments—may be happening and going undetected.</p> <p><strong>For system design</strong>: The capability matrix suggests four outcomes depending on agent and GM sophistication:</p> <table> <thead> <tr> <th> </th> <th>Simple Agent</th> <th>Sophisticated Agent</th> </tr> </thead> <tbody> <tr> <td><strong>Simple GM</strong></td> <td>Baseline cooperation</td> <td>Wasted computation</td> </tr> <tr> <td><strong>Sophisticated GM</strong></td> <td>Environment-carried “cooperation”</td> <td>Genuine strategic cooperation</td> </tr> </tbody> </table> <p>Building sophisticated agents without sophisticated observation is wasteful. Building sophisticated observation without sophisticated agents produces false positives. Both layers need development together.</p> <h2 id="limitations">Limitations</h2> <p><strong>Computational cost</strong> is substantial. Running full cognitive modules on both agent and GM sides burns significant compute per interaction. For large-scale evaluations, this may require sampling or approximation.</p> <p><strong>Empirical validation</strong> against the contest scenarios is future work. The full contest report <d-cite key="smith2024concordia"></d-cite> evaluates the submitted agents but doesn’t test the dual-layer architecture proposed here. Whether sophisticated GM modules would change the rankings remains an open question.</p> <p><strong>Cultural profiles</strong> are reductive. Five discrete profiles can’t capture real cultural variation, which is continuous and contextual. The profiles are useful approximations, not ground truth.</p> <p><strong>Observation regress</strong> is a fundamental issue. Who validates the Game Master? The architecture makes observation explicit rather than implicit, but it doesn’t eliminate the need for human judgment about what counts as strategic cooperation. We’ve moved the problem, not solved it.</p> <h2 id="conclusion">Conclusion</h2> <p>The Concordia Contest found LLM agents failing at strategic cooperation despite succeeding at simpler coordination tasks. The standard fix is to add cognitive modules, so I built them for negotiation scenarios—theory of mind, cultural adaptation, temporal reasoning, uncertainty management, collective intelligence, and adaptive learning.</p> <p>Building revealed that agent cognition is half the problem. Strategic cooperation also needs an observation layer that recognizes strategic behavior. Without it, agents get no feedback on their strategic choices and researchers have no way to measure them.</p> <p>This is the witness problem. It explains why adding cognitive sophistication to agents may not improve measured cooperation—if the measurement can’t see the sophistication, it can’t reward it. Solving the problem requires developing cognitive and observation capabilities together, ensuring that what agents can do, environments can see.</p> <p>The architecture is available to use, extend, or disprove.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/2026/assets/bibliography/2026-04-27-witness-problem.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/beyond-attention-as-graph/">Beyond Attention as a Graph</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/attention-sinks-graph-perspective/">Attention Sinks from the Graph Perspective</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/zero-rewards/">What Can You Do When You Have Zero Rewards During RL?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/why-ai-evaluations-need-error-bars/">Why AI Evaluations Need Error Bars</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/2026/blog/2026/web-agent/">Computer Use Survey - A Visual Survey of Computer Use Agents</a> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ICLR Blog. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/2026/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/2026/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/2026/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/2026/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/2026/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/2026/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/2026/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/2026/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/2026/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/2026/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/2026/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/2026/assets/js/search-data.js"></script> <script src="/2026/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>